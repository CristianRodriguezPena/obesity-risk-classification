{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Predicting obesity \n",
    "This project aims to develope a machine learning model to classify participants based on health and lifestyle survey data, optimizing to ensure higher-risk cases are correctly priorirized.\n",
    "\n",
    "## Problem Statement\n",
    "The goal of this project is to determine a predictive model that accuractly classifies individuals into different obesity levels. Given the ordinal nature of obesity classification, it is important to not only assign the correct class, but also ensure that higher-risk cases are ranked above lower-risk cases.To accomplish this, the model is optimized using the One-vs-One ROC-AUC metric, which evaluates how well the model distinguishes between each pair of obesity levels. This ensures that the model effectively distinguishes between obesity categories and minimizes ranking errors, in turn prioritizing individuals based on obesity risk.\n",
    "\n",
    "## Objective\n",
    "- Develop a machine learning model to classify participants into different obesity levels.\n",
    "- Analyze dataset feature to determine features with the highest impact to predictions.\n",
    "- Compare different classification models and tune hyperparameters to improve generalizations.\n",
    "- Optimize for One-vs-One ROC-AUC to prioritize individuals with higher obesity risk.\n",
    "- Evaluate the model using multiple metrics (Accuracy, F1-score, ROC-AUC)\n",
    "\n",
    "## Dataset feature Description\n",
    "Gender – Male or Female.  \n",
    "Age – The person’s age in years.  \n",
    "Height – Height in meters.  \n",
    "Weight – Weight in kilograms.  \n",
    "family_history_with_overweight – Whether the person has a family history of being overweight (yes/no).  \n",
    "FAVC – If the person frequently consumes high-calorie foods (yes/no).  \n",
    "FCVC – Frequency of vegetable consumption (scale from 1 to 3).  \n",
    "NCP – Number of main meals per day.  \n",
    "CAEC – Frequency of consuming food between meals (Never, Sometimes, Frequently, Always).  \n",
    "SMOKE – Whether the person smokes (yes/no).  \n",
    "CH2O – Daily water intake (scale from 1 to 3).  \n",
    "SCC – If the person monitors their calorie intake (yes/no).  \n",
    "FAF – Physical activity frequency (scale from 0 to 3).  \n",
    "TUE – Time spent using technology (scale from 0 to 3).  \n",
    "CALC – Frequency of alcohol consumption (Never, Sometimes, Frequently, Always).  \n",
    "MTRANS – Main mode of transportation (Automobile, Bike, Motorbike, Public Transportation, Walking).  \n",
    "NObeyesdad – Obesity level (Insufficient Weight, Normal Weight, Overweight Level I, Overweight Level II, Obesity Type I, Obesity Type II, Obesity Type III).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries and load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from src.utils import get_outliers, standardize\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are most of the import we will need for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/ObesityDataSet_raw_and_data_sinthetic.csv\")\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is imported and it has 17 columns and just over 2k rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Missing data:\", df.isna().sum().sum())\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no missing data.  \n",
    "\n",
    "This shows that the dataset has almost an even amount of numerical and categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select_dtypes('number').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of the numerical features have similar ranges, some outliers exist so standardization may be required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_feature_columns = df.select_dtypes(\"object\").columns\n",
    "\n",
    "for col in str_feature_columns:\n",
    "    print(col, \"has\", df[col].unique().size, \"unique values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some categorical features only have 2 categories, therefore these can be turned into boolean features where true/false indicate each of the existing categories.\n",
    "\n",
    "The other categorical features with more than 2 categories, will need more advanced encoding methods. These features will need to be analyzed to determine the appropriate encoding method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = df.select_dtypes(\"number\").columns\n",
    "\n",
    "bins = [20, 20, 20, 20, 20, 20, 20, 20]\n",
    "\n",
    "rows = 2\n",
    "cols = 4\n",
    "fig, axs = plt.subplots(rows, cols, figsize=(16, 8))\n",
    "plt.subplots_adjust(wspace=0.3, hspace=0.2)\n",
    "for i, col in enumerate(numerical_features):\n",
    "    df[col].plot.hist(ax=axs[i//cols, i%cols], bins=bins[i], color=\"teal\")\n",
    "    axs[i//cols, i%cols].title.set_text(col)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of the physiological features (Age, Height, and Weight) resemble a Gaussian curve. Additionally, Age appears to be skewed to the right. \n",
    "\n",
    "The other numerical features have multimodal distributions, with peaks around the integer values of the range. This may produce false positives when detecting outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_features = df.drop(\"NObeyesdad\", axis=1).select_dtypes(\"object\").columns\n",
    "\n",
    "df_display = df.copy()\n",
    "df_display.loc[df_display[\"MTRANS\"] == \"Public_Transportation\", \"MTRANS\"] = \"Public\"\n",
    "\n",
    "rows = 2\n",
    "cols = 4\n",
    "fig, axs = plt.subplots(rows, cols, figsize=(12, 6), sharey=True)\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.7)\n",
    "for i, col in enumerate(category_features):\n",
    "    ax = axs[i//cols, i%cols]\n",
    "    df_display[col].value_counts(normalize=True).plot.bar(ax=ax, color=\"teal\")\n",
    "    ax.set_title(col)\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(\"Frequency\")\n",
    "    \n",
    "    for bar in ax.patches:\n",
    "        height = bar.get_height() / 2 if bar.get_height() > 0.90 else bar.get_height()\n",
    "        \n",
    "        ax.text(bar.get_x() + bar.get_width() / 2, height, \n",
    "                f\"{bar.get_height()*100:.1f}%\", ha=\"center\", va=\"bottom\", \n",
    "                fontsize=8, color=\"black\")\n",
    "    \n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gender feature is well distributed among both genders.  \n",
    "\n",
    "The other categorical features are heavely skewed to one option over all others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"NObeyesdad\"].value_counts(normalize=True).plot.bar(color=\"teal\")\n",
    "plt.title(\"NObeyesdad\")\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "\n",
    "plt.yticks([])\n",
    "\n",
    "\n",
    "for bar in plt.gca().patches:\n",
    "    height = bar.get_height() / 2 if bar.get_height() > 0.90 else bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, height, f\"{bar.get_height()*100:.1f}%\", ha=\"center\", va=\"bottom\", fontsize=8, color=\"black\", weight=\"bold\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target column has a pretty balanced distribution all 7 categories, with all values all between 12% and 17%.\n",
    "\n",
    "All categories in the targe column have a frequency of 12%-17%. Well balanced classes helps create models that predict all classes well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Enginering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turned string values to boolean in Gender: \"Male\" -> True, \"Female\" -> False\n",
    "df = pd.get_dummies(df, columns=[\"Gender\"], drop_first=True)\n",
    "\n",
    "# Turned string values to boolean in family_history_with_overweight: \"yes\" -> True, \"no\" -> False\n",
    "df[\"family_history_with_overweight\"] = (df[\"family_history_with_overweight\"] == \"yes\").astype(\"bool\")\n",
    "df.rename(columns={\"family_history_with_overweight\": \"overweight_family_history\"}, inplace=True)\n",
    "\n",
    "# Turned string values to boolean in FAVC: \"yes\" -> True, \"no\" -> False\n",
    "df[\"FAVC\"] = (df[\"FAVC\"] == \"yes\").astype(\"bool\")\n",
    "\n",
    "# Ordinal encoding CAEC: \"no\" -> 0, \"Sometimes\" -> 1, \"Frequently\" -> 2, \"Always\" -> 3\n",
    "df[\"CAEC\"] = df[\"CAEC\"].astype(pd.CategoricalDtype(categories=[\"no\", \"Sometimes\", \"Frequently\", \"Always\"], ordered=True))\n",
    "\n",
    "# Turned string values to boolean in SMOKE: \"yes\" -> True, \"no\" -> False\n",
    "df[\"SMOKE\"] = (df[\"SMOKE\"] == \"yes\").astype(\"bool\")\n",
    "\n",
    "# Turned string values to boolean in SCC: \"yes\" -> True, \"no\" -> False\n",
    "df[\"SCC\"] = (df[\"SCC\"] == \"yes\").astype(\"bool\")\n",
    "\n",
    "# Ordinal encoding CALC: \"no\" -> 0, \"Sometimes\" -> 1, \"Frequently\" -> 2, \"Always\" -> 3\n",
    "df[\"CALC\"] = df[\"CALC\"].astype(pd.CategoricalDtype(categories=[\"no\", \"Sometimes\", \"Frequently\", \"Always\"], ordered=True))\n",
    "\n",
    "# one\n",
    "df = pd.get_dummies(df, columns=[\"MTRANS\"], drop_first=True)\n",
    "# Dropped category is \"Automobile\"\n",
    "\n",
    "#Ordinal encoding NObeyesdad: \"Insufficient_Weight\" -> 0, \"Normal_Weight\" -> 1, \n",
    "# \"Overweight_Level_I\" -> 2, \"Overweight_Level_II\" -> 3, \"Obesity_Type_I\" -> 4, \n",
    "# \"Obesity_Type_II\" -> 5, \"Obesity_Type_III\" -> 6\n",
    "df[\"NObeyesdad\"] = df[\"NObeyesdad\"].astype(pd.CategoricalDtype(categories=[\"Insufficient_Weight\", \"Normal_Weight\", \n",
    "                                                                           \"Overweight_Level_I\", \"Overweight_Level_II\", \n",
    "                                                                           \"Obesity_Type_I\", \"Obesity_Type_II\", \"Obesity_Type_III\"], ordered=True))\n",
    "\n",
    "df.head()\n",
    "# df[\"CAEC\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This encodes all the categorical features and the target variable. The method for encoding depends of the cardinality of the feature and if the categories are ordinal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BMI is a index used to healthy weight based on height\n",
    "# NOTE: may remove later due to target leakage, the target (NObeyesdad) is based on BMI\n",
    "df[\"bmi\"] = df[\"Weight\"] / (df[\"Height\"]**2)\n",
    "\n",
    "\n",
    "# Higher ratio -> More planned meals and less snacking\n",
    "# Values were standardized before dividing to avoid disconnectivity of the denominator being an interger\n",
    "# Ration is Shifted to start from 1, to improve interpretability\n",
    "df[\"Meal_Balance_Ratio\"] = standardize(df[\"NCP\"]) / standardize(df[\"CAEC\"].cat.codes + 1)\n",
    "df[\"Meal_Balance_Ratio\"] = df[\"Meal_Balance_Ratio\"] - df[\"Meal_Balance_Ratio\"].min() + 1\n",
    "\n",
    "# True if the person uses an active mode of transport\n",
    "df[\"Active_Transport_Indicator\"] = (df[\"MTRANS_Bike\"] == True) | (df[\"MTRANS_Walking\"] == True)\n",
    "\n",
    "cols = 3\n",
    "fig, axs = plt.subplots(1, cols, figsize=(10, 4))\n",
    "fig.suptitle('Categorical Features Frequency', fontsize=24)\n",
    "fig.subplots_adjust(top=0.8, wspace=0.5)\n",
    "\n",
    "df[\"bmi\"].plot.hist(bins=20, color=\"teal\", ax=axs[0])\n",
    "axs[0].title.set_text(\"BMI\")\n",
    "\n",
    "df[\"Meal_Balance_Ratio\"].plot.hist(bins=20, color=\"teal\", ax=axs[1])\n",
    "axs[1].title.set_text(\"Meal_Balance_Ratio\")\n",
    "\n",
    "df[\"Active_Transport_Indicator\"].value_counts().plot.bar(color=\"teal\", ax=axs[2])\n",
    "axs[2].title.set_text(\"Active_Transport_Indicator\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 new derived features are created from the the existing features. These derived features are likely to help the model the complex relationships between the features and target variables.\n",
    "\n",
    "These derived features will show complex relationships between the features to help predict the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = df.select_dtypes(\"category\").columns\n",
    "\n",
    "\n",
    "cols = 3\n",
    "fig, axs = plt.subplots(1, cols, figsize=(12, 5), sharey=True)\n",
    "fig.suptitle('Categorical Features Frequency', fontsize=24)\n",
    "fig.subplots_adjust(top=0.8)\n",
    "\n",
    "for i, col in enumerate(categorical_features):\n",
    "    ax = axs[i]\n",
    "    \n",
    "    freq = df[col].value_counts(normalize=True)\n",
    "    freq.plot.bar(ax=ax, color=\"teal\")\n",
    "    \n",
    "    ax.set_title(col)\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(\"Frequency\")\n",
    "    ax.set_ylim(0, 1)\n",
    "    \n",
    "    for bar in ax.patches:\n",
    "        height = bar.get_height() / (2 if bar.get_height() > 0.90 else 1)\n",
    "        \n",
    "        ax.text(bar.get_x() + bar.get_width() / 2, height, \n",
    "                f\"{bar.get_height()*100:.2f}%\", ha=\"center\", va=\"bottom\", \n",
    "                fontsize=8, color=\"black\")\n",
    "    \n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"Always\" option appears only 0.05% in CALC. This is extremely rare, so it will be useful to merge it with \"Frequently\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"CALC\"] == \"Always\", \"CALC\"] = \"Frequently\"\n",
    "df[\"CALC\"] = df[\"CALC\"].cat.remove_categories([\"Always\"])\n",
    "\n",
    "df[\"CALC\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CALC no longer has a \"Always\" value and the category has also been removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numerical_features = df.select_dtypes(\"number\").columns\n",
    "\n",
    "rows = 2\n",
    "cols = 5\n",
    "fig, axs = plt.subplots(rows, cols, figsize=(12, 8))\n",
    "fig.suptitle('IQR boxplots', fontsize=24)\n",
    "\n",
    "plt.subplots_adjust(wspace=0.35, hspace=0.2)\n",
    "for i, col in enumerate(numerical_features):\n",
    "    outlier_count = get_outliers(df[col], \"iqr\").size\n",
    "    \n",
    "    ax = axs[i//cols, i%cols]\n",
    "    df[col].plot.box(ax=ax, color=\"teal\")\n",
    "    ax.title.set_text(col)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_xlabel(f\"{outlier_count} Outliers (~{outlier_count*100//len(df)}%)\" if outlier_count != 0 else \"No Outliers\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These boxplots show Age, Weight, NCP, and Meal_Balance_Ratio have outliers.  \n",
    "\n",
    "Keeping in mind the distrubution of values of these features Age and Weight have roughly a normal distribution. I want to look at the Z-scores for Age and Weight, before making the decision of removal/replacement.  \n",
    "\n",
    "Looking more into NCP it looks like it has a multimodal distribution with >50% of the values at NCP = 3. With this in mind, I will need to access these outliers further to determine if they are realistic and meaningful or errors/anomalies. ;\n",
    "\n",
    "Meal_Balance_Ratio has 22 outliers from values of 3-4. There values seem normal for now, I will want to see the Z-values for it then decide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = df.select_dtypes(\"number\").columns\n",
    "\n",
    "zscores = df[numerical_features].apply(lambda col: (col - col.mean()) / col.std(), axis=0)\n",
    "\n",
    "df_display = df.copy()\n",
    "\n",
    "rows = 2\n",
    "cols = 5\n",
    "fig, axs = plt.subplots(rows, cols, figsize=(24, 12))\n",
    "fig.suptitle('Z-score scatter plots', fontsize=24)\n",
    "\n",
    "for i, col in enumerate(numerical_features):\n",
    "    outlier_count = get_outliers(zscores[col], \"z-score\").size\n",
    "    \n",
    "    \n",
    "    ax = axs[i//cols, i%cols]\n",
    "    zscores.reset_index().plot.scatter(x=\"index\", y=col, ax=ax, color=\"teal\")\n",
    "    ax.title.set_text(col)\n",
    "    ax.axhline(3, color='Red', label='Z = 3')\n",
    "    ax.axhline(-3, color=\"Blue\", label='Z = -3')\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    ax.set_xticks([])\n",
    "    ax.set_xlabel(f\"{outlier_count} Outliers (~{outlier_count*100//len(df)}%)\" if outlier_count != 0 else \"No Outliers\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These scatter plots show that Age, Weight, and Meal_Balance_Ratio have outliers. \n",
    "\n",
    "The Age feature shows less outliers than the IQR boxplots. This shows that the distribution for age is somewhat normal, because Z-scores analysis shows less outliers. I'm sure there is some overlap in outliers for those feature. I will look at these outliers to deside what to do with them.\n",
    "\n",
    "The Weight feature has one outlier at about a z-score of 3.1. I will review it and take a look if it should be removed or changed.\n",
    "\n",
    "This shows no outliers in NCP and Meal_Balance_Ratio, which makes sense since Z-scores takes standard deviation into account, instead of the quadrants of IQR box plots. I will see the overlap between these two detection methods to decide what to do next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_iqr_outliers = get_outliers(df[\"Age\"], \"iqr\")\n",
    "print(\"Age has\", len(age_iqr_outliers), \"IQR outliers.\")\n",
    "age_zscore_outliers = get_outliers(df[\"Age\"], \"z-score\")\n",
    "print(\"Age has\", len(age_zscore_outliers), \"Z-score outliers.\")\n",
    "\n",
    "age_outliers = df.loc[age_iqr_outliers.index.intersection(age_zscore_outliers.index), \"Age\"]\n",
    "print(\"Age has\", age_outliers.shape[0], \"outliers overlapping in both methods.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking at the outliers from IQR and Z-scores it looks like there is 100% overlap. I think the distribution of Age is slightly normal, therefore the z-scores is a better outlier detection method for this feature. In lieu of those I have desided to explore the 23 outliers (given from z-score detection).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Age outlier min:\", age_outliers.min())\n",
    "print(\"Age outlier max:\", age_outliers.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Age outliers seem to range from 44 - 61 years of age. These values are not outliers and completely normal. Since the outliers are normal and meaningful, I will keep them all. Looking at the previous graphs of the distribution of age they dont seem to be any error or anomaly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[zscores[\"Weight\"] > 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After examining the outlier in Weight from both Z-scores and IQR, I have decided to keep it. I think its a resonable to weigh 160 Kg. I dont think it is anomaly either: it is only slightly outside the box plot whiskers, and a z-score of ~3.1. I also dont think that this participant will influence the model too much as they also have a height of 1.87. This height is among the highest so their weight being high as well is not too influencial, not an anomaly, nor an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"NCP IQR:\", round(df[\"NCP\"].quantile(0.75) - df[\"NCP\"].quantile(0.25), 2))\n",
    "\n",
    "NCP_iqr_outliers = get_outliers(df[\"NCP\"], \"iqr\")\n",
    "print(\"NCP has\", len(NCP_iqr_outliers), \"IQR outliers.\")\n",
    "\n",
    "NCP_zscore_outliers = get_outliers(zscores[\"NCP\"], \"z-score\")\n",
    "print(\"NCP has\", len(NCP_zscore_outliers), \"Z-score outliers.\")\n",
    "\n",
    "print(\"Meal_Balance_Ratio IQR:\", round(df[\"Meal_Balance_Ratio\"].quantile(0.75) - df[\"Meal_Balance_Ratio\"].quantile(0.25), 2))\n",
    "\n",
    "NCP_iqr_outliers = get_outliers(df[\"Meal_Balance_Ratio\"], \"iqr\")\n",
    "print(\"Meal_Balance_Ratio has\", len(NCP_iqr_outliers), \"IQR outliers.\")\n",
    "\n",
    "NCP_zscore_outliers = get_outliers(zscores[\"Meal_Balance_Ratio\"], \"z-score\")\n",
    "print(\"Meal_Balance_Ratio has\", len(NCP_zscore_outliers), \"Z-score outliers.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For NCP there is a huge discrepency in outliers in both detection methods. The difference between 580 and 0 is big. This is likely due to the multimodal nature of the distribution where the inner-quantile range being only 0.34 because 50% of the values lie on the median. For this reason I will explore percentile-based outlier detection to take into account where the extreme values are based on the nature of the distribution.  \n",
    "\n",
    "Similar to NCP, IQR-based detection has detected alot of outliers for Meal_Balance_Ratio, while Z-scores-based detection found none. The difference being 407 outliers. Again this is likely due to the multimodal nature of the distribution where the inner-quantile range being only 1.57 because 50% of the values lie on the median. For this reason I will explore percentile outlier detection to take into account where the extreme values are based on the nature of the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the 99th percentile to get the outliers\n",
    "# 99% is equivalent to 1.5× IQR, a widely used robust measure for detecting outliers in non-normally distributed data.\n",
    "threshold = 0.99\n",
    "\n",
    "NCP_percentile_outliers = get_outliers(df[\"NCP\"], \"percentile\")\n",
    "print(\"NCP has\", len(NCP_percentile_outliers), \"outliers beyond 99th percentile.\")\n",
    "\n",
    "NCP_percentile_outliers = get_outliers(df[\"Meal_Balance_Ratio\"], \"percentile\")\n",
    "print(\"Meal_Balance_Ratio has\", len(NCP_percentile_outliers), \"outliers beyond 99th percentile.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since percentile-based detection found 0 outliers in both NCP and Meal_Balance_Ratio beyond the 99th percentile, I will conclude there are no true outliers. This aligns with my assumption that Percentile-based detection is more appropriate than IQR in these features, as it does not rely on IQR's fixed spread and instead dynamically adapts to the distribution of values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Before any type of modeling, we need to remove the features related to weight to prevent target leakage\n",
    "df.drop([\"bmi\", \"Weight\"], axis=1, inplace=True)\n",
    "\n",
    "# Turn categorical features into numerical\n",
    "cat_cols = df.select_dtypes('category').columns\n",
    "df[cat_cols] = df[cat_cols].apply(lambda col: col.cat.codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "corr = df.corr()\n",
    "corr = corr.apply(lambda col: col.apply(lambda x: 0 if abs(x) < 0.1 else x), axis=0)\n",
    "sns.heatmap(corr, annot=True, cmap=\"crest\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the correlation heatmap I can tell there is some good correlation between the target variable and other features. I will explore linear regression for classification.  \n",
    "\n",
    "I think the dataset has some pretty complex relationships which leads me to believe tree based models can perform good as well. If there is overfitting, then I will consider ensemble tree models to generalize better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = df.drop(\"NObeyesdad\", axis=1)\n",
    "y = df[\"NObeyesdad\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Linear models need scaled data to preform well\n",
    "X_train_scaled = StandardScaler().set_output(transform=\"pandas\").fit_transform(X_train)\n",
    "X_test_scaled = StandardScaler().set_output(transform=\"pandas\").fit_transform(X_test)\n",
    "\n",
    "linear_model = LogisticRegression(n_jobs=-1, random_state=42)\n",
    "tree_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "linear_model.fit(X_train_scaled, y_train)\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Linear model train accuracy:\", round(linear_model.score(X_train_scaled, y_train)*100, 2))\n",
    "print(\"Linear model test accuracy:\", round(linear_model.score(X_test_scaled, y_test)*100, 2))\n",
    "print(\"Tree model train accuracy:\", round(tree_model.score(X_train, y_train)*100, 2))\n",
    "print(\"Tree model test accuracy:\", round(tree_model.score(X_test, y_test)*100, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these train and testing scores I can conclude that Logistic regression is not overfitting, but performance is relitively low, suggesting there is a lack of a strong linear relationship with in the data. \n",
    "\n",
    "On the other hand, the decision tree shows severe overfitting, with a perfect 100% train accuracy, but only a 77% test accuracy. Despite this, the test scores are still a strong indicator that tree-based models capture the petterns within the data.\n",
    "\n",
    "With proper hyperparameter tuning, tree-based models have the protential to provide strong predictive performance while reducing overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature importance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "\n",
    "tree_results = permutation_importance(tree_model, X_test, y_test, scoring=\"roc_auc_ovo\", n_repeats=10, random_state=42)\n",
    "importances = pd.Series(tree_results.importances_mean, index=X.columns)\n",
    "importances = importances.sort_values(ascending=False)\n",
    "\n",
    "tree_sorted_idx = tree_results.importances_mean.argsort()\n",
    "tree_sorted_idx = tree_sorted_idx[::-1]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "importances.plot.barh(color=\"teal\")\n",
    "plt.xlabel(\"Permutation Importance\")\n",
    "plt.ylabel(\"Features\")\n",
    "plt.title(\"Tree Model\")\n",
    "\n",
    "#label bar values\n",
    "for i, v in enumerate(importances):\n",
    "    plt.text(v if v < 0.25 else v/2, i, str(round(v, 2)), va=\"center\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the feature importance bar chart reveals that there is a steep drop off after MTRANS_Public_Transportation (Importance = 0.03). Based on this, I will use a cutoff of 0.03 and retain only features with higher importance for predictive modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "importances = importances[importances > 0.02].sort_values(ascending=False)\n",
    "\n",
    "X = df.drop(\"NObeyesdad\", axis=1)[importances.index]\n",
    "y = df[\"NObeyesdad\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "params = {\n",
    "    \"max_depth\": [None, 5, 10, 20],\n",
    "    \"min_samples_split\": [2, 5, 10, 20, 30],\n",
    "    \"min_samples_leaf\": [1, 5, 10],\n",
    "    \"max_features\": [None, \"sqrt\", \"log2\"],\n",
    "    \"ccp_alpha\": [0, 0.001, 0.01, 0.1],\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"random_state\": [42]\n",
    "}\n",
    "\n",
    "\n",
    "scoring = \"roc_auc_ovo\"\n",
    "tree_search_cv = GridSearchCV(DecisionTreeClassifier(), \n",
    "                                   params,\n",
    "                                   cv=5, \n",
    "                                   n_jobs=-1, \n",
    "                                   scoring=scoring,\n",
    "                                   verbose=1)\n",
    "\n",
    "tree_search_cv.fit(X, y)\n",
    "tree_search_cv.scorer_\n",
    "print(\"Best params:\", tree_search_cv.best_params_)\n",
    "print(f\"Best {scoring} score:\", tree_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the parameter search performed using GridSearchCV, the model selected an estimator with the listed parameters. These hyperparameters resulted in the highest ROC-AUC score of 0.912, indicating that the model effectively distinguishes between different obesity levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "\n",
    "y_pred = cross_val_predict(tree_search_cv.best_estimator_, X, y, cv=5, n_jobs=-1)\n",
    "y_pred_proba = cross_val_predict(tree_search_cv.best_estimator_, X, y, cv=5, n_jobs=-1, method=\"predict_proba\")\n",
    "print(\"ROC-AUC-OVO Score\", roc_auc_score(y, y_pred_proba, multi_class=\"ovo\"))\n",
    "\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification report shows that after hyperparameter tuning and feature importance analysis, the Decision tree model achieves an accuracy of 74%. This is slightly lower than before tuning, indicating that the model has become more generalized.\n",
    "\n",
    "Additionally, the model predicts Obesity Type 3 (Class 6) exceptionally well, achieving a 98% accuracy with a 99% recall and 96% prescision. This demonstrates the model is very strong at indentifying extreme obesity cases.\n",
    "\n",
    "While the model performs well overall, mid-level obesity classifications (Classes 1-4) have slightly lower prescision and recall. This could be improved thorugh further feature engineering efforts or utilizing advance ensemble techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have successfully achieved my goal of predicting obesity level using survey health data. Through feature engineer, outlier detection, hyperparameter tuning, and ROC-AUC optimizations, I have developed a model that predicts obesity at 74% accuracy with a 0.912 ROC-AUC score. \n",
    "\n",
    "The model performs strongly in extreme obesity cases, but has a slight weakness in mid-level obesity categories. While it effectively indentifies severe obesity cases, distinguishing between moderate obesity is still a challange for the model.\n",
    "\n",
    "To further improve this further, additional feature engineering could be explored to develop more advance features that enchance the predictive power. Additionally, ensemble models like Random Forest Tree, could help generalizes better, leading to more balanced scores across the prediction classes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_learn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
